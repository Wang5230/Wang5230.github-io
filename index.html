<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>Kopaba</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Speak softly and carry a big stick; you will go far">
<meta property="og:type" content="website">
<meta property="og:title" content="Kopaba">
<meta property="og:url" content="https://www.wang5230.github.io/index.html">
<meta property="og:site_name" content="Kopaba">
<meta property="og:description" content="Speak softly and carry a big stick; you will go far">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kopaba">
<meta name="twitter:description" content="Speak softly and carry a big stick; you will go far">
  
    <link rel="alternate" href="/atom.xml" title="Kopaba" type="application/atom+xml">
  
  
  
  <link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">
  <link rel="stylesheet" href="/lib/fancybox/dist/jquery.fancybox.min.css">
  <link rel="stylesheet" href="/css/main.css">
  <script src="/lib/jquery/dist/jquery.min.js"></script>
  
  
  
  
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head></html>
<body>
  <div id="wrapper">
    <header id="header" class="clearfix">
	<a id="logo" href="/" title="Kopaba">Kopaba</a>
	
		<p class="description">Imagination is the essence of discovery</p>
	
	<nav id="nav-menu" class="clearfix">
		<form id="search" method="post" action="./" role="search">
			<input id="search-input" type="text" name="s" class="inputbox" value="Search" onfocus="if (value =='Search'){value =''}" onblur="if (value ==''){value='Search'}">
		</form>
		<ul>
      
				
        <li><a class="main-nav-link" href="/">Home</a></li>
      
				
        <li><a class="main-nav-link" href="/archives">Archives</a></li>
      
		</ul>
	</nav>
</header>
    <section id="main" class="clearfix">
  <article class="post">
      
        
          <h1><a href="/2023/03/15/py-in-met/">py in met</a></h1>
        
      
      <div class="post-content ">
        
  




        <h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>这篇博客主要记录在使用python进行气象数据处理/绘制中的一些问题<br><strong>np.meshgrid(lon_grid,lat_grid)</strong> 可以将经纬度转换为对应的坐标点<br><strong>xarray.Dataarray</strong> 具有标签属性(例如lat，lon)<br> <strong>numpy.array</strong>不具有标签属性</p>

      </div>
  </article>

  <article class="post">
      
        
          <h1><a href="/2023/03/08/GPM/">GPM</a></h1>
        
      
      <div class="post-content ">
        
  




        <h1 id="数据介绍"><a href="#数据介绍" class="headerlink" title="数据介绍"></a>数据介绍</h1><p>GPM数据分为两类</p>
<ol>
<li>观测后4小时与十四小时的逐半小时0.1x0.1资料</li>
<li>观测后3.5月后的逐月0.1x0.1资料</li>
</ol>
<h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><ol>
<li>将观测资料进行质量控制，筛除缺测，通过时间对缺测全天的数据索引进行标记，之后将GPM资料做相同处理，进行相关系数等的计算</li>
<li>论文中讲述顺序要由大到小，由总体到局部</li>
</ol>
<h1 id="脚本留档"><a href="#脚本留档" class="headerlink" title="脚本留档"></a>脚本留档</h1><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">import</span> MultipleLocator
<span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>ticker <span class="token keyword">import</span> FuncFormatter
<span class="token keyword">import</span> os
<span class="token keyword">import</span> cartopy<span class="token punctuation">.</span>crs <span class="token keyword">as</span> ccrs
<span class="token keyword">from</span> cartopy<span class="token punctuation">.</span>io<span class="token punctuation">.</span>shapereader <span class="token keyword">import</span> Reader
<span class="token keyword">import</span> cartopy<span class="token punctuation">.</span>feature <span class="token keyword">as</span> cfeat
<span class="token keyword">import</span> xarray <span class="token keyword">as</span> xr
<span class="token keyword">import</span> matplotlib <span class="token keyword">as</span> mpl
<span class="token keyword">import</span> h5py
<span class="token keyword">from</span> scipy <span class="token keyword">import</span> interpolate <span class="token keyword">as</span> ip
<span class="token keyword">import</span> shapefile
<span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>path <span class="token keyword">import</span> Path
<span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>patches <span class="token keyword">import</span> PathPatch
mpl<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'font.family'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'sans-serif'</span>
mpl<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'font.sans-serif'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Times New Roman'</span><span class="token punctuation">]</span>
mpl<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'axes.unicode_minus'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>
<span class="token keyword">def</span> <span class="token function">to_latitude</span><span class="token punctuation">(</span>temp<span class="token punctuation">,</span> position<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token string">'%1.0f'</span><span class="token operator">%</span><span class="token punctuation">(</span>temp<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'°N'</span>
<span class="token keyword">def</span> <span class="token function">to_longtitude</span><span class="token punctuation">(</span>temp<span class="token punctuation">,</span>position<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token string">'%1.0f'</span><span class="token operator">%</span><span class="token punctuation">(</span>temp<span class="token punctuation">)</span><span class="token operator">+</span> <span class="token string">'°E'</span>
<span class="token keyword">def</span> <span class="token function">to_time</span><span class="token punctuation">(</span>temp<span class="token punctuation">,</span>position<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> temp <span class="token operator">&lt;</span> <span class="token number">10</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token string">'0'</span><span class="token operator">+</span><span class="token string">'%1.0f'</span><span class="token operator">%</span><span class="token punctuation">(</span>temp<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">':00'</span>
    <span class="token keyword">return</span> <span class="token string">'%1.0f'</span><span class="token operator">%</span><span class="token punctuation">(</span>temp<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">':00'</span>         <span class="token comment" spellcheck="true">##转换坐标轴</span>
<span class="token keyword">def</span> <span class="token function">countLine</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">:</span> 
    count <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span>
    <span class="token keyword">for</span> count<span class="token punctuation">,</span>line <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>open<span class="token punctuation">(</span>file_path<span class="token punctuation">,</span><span class="token string">'r'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>
        count <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token keyword">return</span> count


<span class="token keyword">def</span> <span class="token function">shp2clip</span><span class="token punctuation">(</span>originfig<span class="token punctuation">,</span> ax<span class="token punctuation">,</span> shpfile<span class="token punctuation">,</span> regionlist<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true">#白化函数 将contour在shp区域外转为白色</span>
    sf <span class="token operator">=</span> shapefile<span class="token punctuation">.</span>Reader<span class="token punctuation">(</span>shpfile<span class="token punctuation">)</span>
    vertices <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    codes <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> shape_rec <span class="token keyword">in</span> sf<span class="token punctuation">.</span>shapeRecords<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        region_name <span class="token operator">=</span> shape_rec<span class="token punctuation">.</span>record<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true">#是否是[0]得自行分析自己的shp文件</span>
        <span class="token keyword">if</span> region_name <span class="token keyword">in</span> regionlist<span class="token punctuation">:</span> 
            pts <span class="token operator">=</span> shape_rec<span class="token punctuation">.</span>shape<span class="token punctuation">.</span>points
            prt <span class="token operator">=</span> list<span class="token punctuation">(</span>shape_rec<span class="token punctuation">.</span>shape<span class="token punctuation">.</span>parts<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>len<span class="token punctuation">(</span>pts<span class="token punctuation">)</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>prt<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>prt<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> prt<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    vertices<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>pts<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> pts<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                codes <span class="token operator">+=</span> <span class="token punctuation">[</span>Path<span class="token punctuation">.</span>MOVETO<span class="token punctuation">]</span>
                codes <span class="token operator">+=</span> <span class="token punctuation">[</span>Path<span class="token punctuation">.</span>LINETO<span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token punctuation">(</span>prt<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> prt<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span>
                codes <span class="token operator">+=</span> <span class="token punctuation">[</span>Path<span class="token punctuation">.</span>CLOSEPOLY<span class="token punctuation">]</span>
            clip <span class="token operator">=</span> Path<span class="token punctuation">(</span>vertices<span class="token punctuation">,</span> codes<span class="token punctuation">)</span>
            clip <span class="token operator">=</span> PathPatch<span class="token punctuation">(</span>clip<span class="token punctuation">,</span> transform<span class="token operator">=</span>ax<span class="token punctuation">.</span>transData<span class="token punctuation">)</span>
    <span class="token keyword">for</span> contour <span class="token keyword">in</span> originfig<span class="token punctuation">.</span>collections<span class="token punctuation">:</span>
        contour<span class="token punctuation">.</span>set_clip_path<span class="token punctuation">(</span>clip<span class="token punctuation">)</span>

    <span class="token keyword">return</span> clip
<span class="token comment" spellcheck="true">##shp2clip(tt,ax,sy,['辽宁省'])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

      </div>
  </article>

  <article class="post">
      
        
          <h1><a href="/2022/12/03/bash/">bash</a></h1>
        
      
      <div class="post-content ">
        
  




        <h1 id="Debug"><a href="#Debug" class="headerlink" title="Debug"></a>Debug</h1><h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><ol>
<li>在windows下vscode中配置<em>git bash</em>时要注意默认的终端选项中git bash中间的空格，会导致vscode不识别。同时在1.75.1版本的vscode中修改默认终端的选项为terminal.integrated.defaultProfile.windows</li>
</ol>

      </div>
  </article>

  <article class="post">
      
        
          <h1><a href="/2022/09/25/WRF学习/">WRF学习</a></h1>
        
      
      <div class="post-content ">
        
  




        <h2 id="debug"><a href="#debug" class="headerlink" title="debug"></a>debug</h2><h3 id="1"><a href="#1" class="headerlink" title="1"></a>1</h3><p>在运行 <strong>./geogrid.exe</strong> 出现cannot open shared object file:libifport.so.5 No such file or directory，通过在环境变量中增加寻找动态链接库方法解决未果，通过搜索发现有人说在适用intel编译器(或ia32)，应该总输入 <strong>source /opt/intel/bin/compilervars.sh intel64</strong></p>
<h3 id="2"><a href="#2" class="headerlink" title="2"></a>2</h3>
      </div>
  </article>

  <article class="post">
      
        
          <h1><a href="/2022/09/22/Fortran学习/">Fortran学习</a></h1>
        
      
      <div class="post-content ">
        
  




        <h1 id="baisc语法"><a href="#baisc语法" class="headerlink" title="baisc语法"></a>baisc语法</h1><h2 id="基本构成"><a href="#基本构成" class="headerlink" title="基本构成"></a>基本构成</h2><p>fortran程序由一组程序单元组成，每个包含一个主程序，语法如下</p>
<pre class="line-numbers language-fortran"><code class="language-fortran"><span class="token keyword">program</span> program_name
<span class="token keyword">implicit none</span>
<span class="token keyword">end program</span> program_name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h2 id="命名以及字符集"><a href="#命名以及字符集" class="headerlink" title="命名以及字符集"></a>命名以及字符集</h2><p>与C语言所包含的ASCII字符集基本相同，标识符即变量名称不区分大小写，且第一个字符必须是字母</p>
<h2 id="关键字"><a href="#关键字" class="headerlink" title="关键字"></a>关键字</h2><p><a href="https://wenku.baidu.com/view/08bea464cfbff121dd36a32d7375a417866fc109.html" target="_blank" rel="noopener">https://wenku.baidu.com/view/08bea464cfbff121dd36a32d7375a417866fc109.html</a></p>
<h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p>分为了5种包括整数，浮点数，复杂数，布尔类型，字符类型</p>
<ol>
<li>整数(integer)与C语言中的int类似，仅保存整数</li>
<li>浮点数(real)默认类型为双精度浮点数，可通过<strong>kind</strong>函数对其以及整数进行精度控制，对整数是控制其所占字节大小，通过<strong>huge</strong>函数可以得到某一整数变量的最大值。通过数字后加<strong>d0</strong>来声明数字为双精度实数</li>
<li>复杂类型(complex)用于存储复数，赋值有两种方式，无论输入参数如何，其实部和虚部均为单精度</li>
</ol>
<pre class="line-numbers language-fortran"><code class="language-fortran"><span class="token keyword">complex</span> <span class="token operator">::</span> cx
cx <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token punctuation">,</span> <span class="token number">2.0</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">! cx = 1+2i</span>
cx <span class="token operator">=</span> cmplx<span class="token punctuation">(</span><span class="token number">2.0</span> <span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">! cx = 2+i</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<ol start="4">
<li>字符类型(character)用于存储字符串，通过<strong>len</strong>声明其长度</li>
</ol>
<pre class="line-numbers language-fortran"><code class="language-fortran"><span class="token keyword">character</span><span class="token punctuation">(</span>len <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span> <span class="token operator">::</span> name <span class="token comment" spellcheck="true">!声明了一个长度为40，名称为name的字符串</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<ol start="5">
<li><p>逻辑类型(logical)用于存储逻辑布尔值</p>
</li>
<li><p>对常量的声明，通过使用<strong>parameter</strong>关键字</p>
</li>
</ol>
<pre class="line-numbers language-fortran"><code class="language-fortran"><span class="token keyword">integer</span> <span class="token punctuation">,</span> <span class="token keyword">parameter</span> <span class="token operator">::</span> const <span class="token operator">=</span> <span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<ol start="5">
<li>动态数组(Dynamic Arrays)编译时大小未知，执行时已知，通过<strong>allocatable</strong>来声明动态数组，必须声明数组的维度，通过<strong>allocate</strong>函数，随后可以通过deallocate来释放内存</li>
</ol>
<h2 id="算术运算符"><a href="#算术运算符" class="headerlink" title="算术运算符"></a>算术运算符</h2><p>基本的数学运算符以及关系运算符(== , &gt;=…)与C基本相同，逻辑运算符与ncl相同,在含有等于的运算符多了一个v(如.eq.变为了.eqv.)</p>
<h2 id="条件语句"><a href="#条件语句" class="headerlink" title="条件语句"></a>条件语句</h2><p>与C类似，不同的是switch case 变为了 select  case</p>
<h2 id="循环语句"><a href="#循环语句" class="headerlink" title="循环语句"></a>循环语句</h2><p>使用<strong>do</strong>或者<strong>do while</strong>来控制循环，循环可以嵌套，且存在内部声明的变量为局部变量，使用<strong>exit</strong>来退出循环，<strong>cycle</strong>作用类似于continue</p>
<h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><ol>
<li><p>通过<strong>subroutine</strong>关键字来声明函数也称为子程序，在主函数中通过call来调用,fortran中函数的返回值较为特殊，在subroutine声明的函数中需要将返回值也作为函数参数声明，bingqie</p>
</li>
<li><p>通过<strong>function</strong>声明,需要注意在主函数中声明函数与函数类型，且结果返回值以函数名为结果，即返回 <strong>函数名=expression</strong>，同时函数中需要对参数进行声明时加上<strong>intent(in)</strong>关键字，并且此时参数为局部变量，变量不可修改，声明<strong>intent(out)</strong>变量不可为函数参数，但可以修改且可向外输送；<strong>intent(inout)</strong>既可以作为参数同时也可作为输出的结果，效果等同不声明intent，一般来说，在函数中其优势为局部变量，intent应该总为in，如果要使用其他的intent则应该使用subroutine热不是function</p>
</li>
</ol>

      </div>
  </article>

  <article class="post">
      
        
          <h1><a href="/2022/01/02/2021年总结/">2021年总结</a></h1>
        
      
      <div class="post-content ">
        
  




        <p>回顾这一年确实发生了许多事情，但最值得回味的还是准备考试的那段时间，尽管相比真正的刻苦努力的人还是有所差距，但也是尽力而为了，希望来年能得到一个好的结果。也很感激这大半年身边人的支持，唯一美中不足就是。。</p>

      </div>
  </article>

  <article class="post">
      
        
          <h1><a href="/2020/10/29/data-augmentation/">data augmentation</a></h1>
        
      
      <div class="post-content ">
        
  




        <p>(1)将图像从左向右翻转<br>(2)将图像从上到下翻转<br>(3)对角翻转图像<br>(4)调整图像亮度，最大delta设置为0.4<br>(5)调整图像对比度，将比例从0.8调至1.2<br>(6)调整图像色相，将最大差值设置为0.5<br>(7)调整图像饱和度，将比例从0.8设置为1.2<br>(8)将图像旋转90度、180度和270度。</p>

      </div>
  </article>

  <article class="post">
      
        
          <h1><a href="/2020/10/29/batch-epoch-iteration/">batch,epoch,iteration</a></h1>
        
      
      <div class="post-content ">
        
  




        <ol>
<li><p>batch size：简单来说，batch size就是每次训练向模型中传入的数据量的多少，过小的话会导致梯度不明显，模型下降速度慢，过大的话尽管速度会更快但会导致需要更多的epoch来获得更好的结果，与batch本身的节约内存空间的目的相悖，因此需要选择一个合适的batch大小来进行训练。</p>
</li>
<li><p>iteration:意思为迭代，一个iteration等于将batch size中的数据迭代一遍</p>
</li>
<li><p>epoch:意思为周期，一个周期相当于将样本中的所有数据遍历一遍。例如样本数量为1000，batch size为10，那么就需要100此iteration来完成一个epoch。</p>
</li>
</ol>

      </div>
  </article>

  <article class="post">
      
        
          <h1><a href="/2020/09/05/Machine_learing/">MachineLearning</a></h1>
        
      
      <div class="post-content ">
        
  




        <h2 id="监督式学习"><a href="#监督式学习" class="headerlink" title="监督式学习"></a>监督式学习</h2><p>指目标给定标签来进行分类等例如聚类，分类问题等</p>
<h2 id="无监督式学习"><a href="#无监督式学习" class="headerlink" title="无监督式学习"></a>无监督式学习</h2><p>指目标没有指定的标签，通过已有样本的特点来进行预测拟合，如回归分析</p>
<h3 id="构成"><a href="#构成" class="headerlink" title="构成"></a>构成</h3><ol>
<li><p>代价函数(一般为平方差等，表示拟合量与实际值的偏差)通过寻找代价函数与目标函数参数关系寻找到最小值来进行回归。</p>
</li>
<li><p>梯度下降法，通过遍历寻找在当前点梯度最大方向进行遍历，类似于贪心的思想，来降低代价函数值寻找局部最小值(注意，这里并不是全局的最小值)，越大的学习系数每一步的步长越长，需要注意的是每次要做到每个系数的同步跟新。<br>通过画出代价函数变化函数来确定是否收敛，一般在学习速率够小时，代价函数都会随着迭代而减小，但过小会导致收敛速度慢的问题</p>
</li>
<li><p>反向传播：包含两个阶段，激励传播与权重更新</p>
<ul>
<li>激励传播：包含两步，第一步前向传播阶段，将输入送入网络获得激励响应；第二部，求出代价函数，一般为方差获得输出层和隐藏层的误差</li>
<li>权重更新：根据代价函数对于不同权重敏感程度以及各个激活值距离正确值的大小来决定，例如在有两个神经元一个激活值为0.2其期望值是1，一个是0.3其期望值是0，那么需要优先调整距离期望较大的神经元</li>
<li></li>
</ul>
</li>
</ol>

      </div>
  </article>

  <article class="post">
      
        
          <h1><a href="/2020/08/26/TensorFlow/">TensorFlow1.x学习笔记</a></h1>
        
      
      <div class="post-content ">
        
  




        <h2 id="debug"><a href="#debug" class="headerlink" title="debug"></a>debug</h2><h3 id="module-‘tensorflow’-has-no-attribute-‘Session’-已修复"><a href="#module-‘tensorflow’-has-no-attribute-‘Session’-已修复" class="headerlink" title="module ‘tensorflow’ has no attribute ‘Session’(已修复)"></a>module ‘tensorflow’ has no attribute ‘Session’(已修复)</h3><p>在新版本中Tensorflow 2.0版本中已经移除了Session这一模块，改换运行代码以及对于graph的语法皆以变化，语法近似pytorch</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
tf<span class="token punctuation">.</span>compat<span class="token punctuation">.</span>v1<span class="token punctuation">.</span>disable_eager_execution<span class="token punctuation">(</span><span class="token punctuation">)</span>
config <span class="token operator">=</span> tf<span class="token punctuation">.</span>compat<span class="token punctuation">.</span>v1<span class="token punctuation">.</span>ConfigProto<span class="token punctuation">(</span>allow_soft_placement<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
sess<span class="token operator">=</span> tf<span class="token punctuation">.</span>compat<span class="token punctuation">.</span>v1<span class="token punctuation">.</span>Session<span class="token punctuation">(</span>config<span class="token operator">=</span>config<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="建立一个简单的回归分析模型"><a href="#建立一个简单的回归分析模型" class="headerlink" title="建立一个简单的回归分析模型"></a>建立一个简单的回归分析模型</h2><ol>
<li>首先使用placeholder为输入与输出创建占位符，同时为权重和截距创建合适的变量</li>
</ol>
<pre class="line-numbers language-pyhton"><code class="language-pyhton">x = tf.placeholder(tf.float32 , shape = [None ,3]) #输入
y_ture = tf.placeholder(tf.float32 , shape = None) #实际值
w = tf.Variable([[0,0,0]] , dtype = tf.float32 , 
name = 'weights')  #权重
b = tf.Variable(0 , dtype = tf.float32 , name = 'bias') #截距
y_pred = tf.matmul(w , tf.transpose(x)) + b #预测值<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol start="2">
<li>接下来，需要来评估模型的性能，为了刻画预测值与真实值的差异，需要订一个反应“距离”的度量，一般称为<strong>损失函数</strong>，通过寻找一组参数来最小化损失函数优化模型。一般使用<strong>MSE(均方差)和交叉熵</strong></li>
</ol>
<pre class="line-numbers language-pyhton"><code class="language-pyhton">#-----------------MRE
loss = tf.reduce_mean(tf.square(y_ture - y_pred)) #MSE
#----------------交叉熵
loss = tf.nn.sigmod_cross_entropy_with_logits(lables = y_ture , logits = y_pred)
loss = tf.reduce_mean(loss)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol start="3">
<li><p>接下来需要明白如何最小化损失函数，一般使用<strong>梯度下降法</strong>，尽管可能陷入局部最优，但是一般都是足够好的。</p>
</li>
<li><p>由于计算整个样本集合可能会很慢，所以需要使用一些采样方法，对样本的子集进行采样，一般规模在50~500个一次，过小的样本会使得硬件利用率降低，而且会使得<strong>目标函数</strong>产生较大的波动，但有时波动也是有益的，因为能够使得参数跳跃到新的局部最优值，TF中通过向图中添加新的操作然后使用自动差分来计算梯度，需要设置的就是学习率，来确定每次更新迭代的量，一般更倾向于设置较小的学习率，以防止跳过了局部最优解，但过低会导致损失函数减少的十分慢。</p>
</li>
</ol>
<pre class="line-numbers language-python"><code class="language-python">optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>GradientDsecentOptimizer<span class="token punctuation">(</span>learning_rate<span class="token punctuation">)</span>
train <span class="token operator">=</span> optimizer<span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><p>使用numpy生成数据，创建了三个特征向量样本，每个样本内积乘以一组权重加上偏差项再加上噪声得出结果，通过优化模型找到最佳参数</p>
<pre class="line-numbers language-python"><code class="language-python">
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> tensorflow<span class="token punctuation">.</span>compat<span class="token punctuation">.</span>v1 <span class="token keyword">as</span> tf
tf<span class="token punctuation">.</span>disable_eager_execution<span class="token punctuation">(</span><span class="token punctuation">)</span>
x_data <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2000</span> <span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
w_real <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.3</span> <span class="token punctuation">,</span> <span class="token number">0.5</span> <span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span>
b_real <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">0.2</span>

noise <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2000</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">0.1</span>
y_data <span class="token operator">=</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>w_real <span class="token punctuation">,</span> x_data<span class="token punctuation">.</span>T<span class="token punctuation">)</span> <span class="token operator">+</span> b_real <span class="token operator">+</span> noise
<span class="token comment" spellcheck="true">#生成数据</span>
NUM_STEPS <span class="token operator">=</span> <span class="token number">11</span>
wb <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
g <span class="token operator">=</span> tf<span class="token punctuation">.</span>Graph<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> g<span class="token punctuation">.</span>as_default<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32 <span class="token punctuation">,</span> shape <span class="token operator">=</span> <span class="token punctuation">[</span>None <span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    y_true <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32 <span class="token punctuation">,</span>shape<span class="token operator">=</span>None<span class="token punctuation">)</span>
    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'inference'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> scope<span class="token punctuation">:</span>
        w <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token punctuation">,</span> dtype <span class="token operator">=</span> tf<span class="token punctuation">.</span>float32 <span class="token punctuation">,</span> name <span class="token operator">=</span> <span class="token string">'weights'</span><span class="token punctuation">)</span>
        b <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span><span class="token number">0</span> <span class="token punctuation">,</span> dtype <span class="token operator">=</span> tf<span class="token punctuation">.</span>float32 <span class="token punctuation">,</span> name <span class="token operator">=</span> <span class="token string">'bias'</span><span class="token punctuation">)</span>
        y_pred <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>w <span class="token punctuation">,</span> tf<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> b

    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> scope<span class="token punctuation">:</span>
        loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>square<span class="token punctuation">(</span>y_true <span class="token operator">-</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'train'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> scope<span class="token punctuation">:</span>
        learning_rate <span class="token operator">=</span> <span class="token number">0.5</span>
        optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>GradientDescentOptimizer<span class="token punctuation">(</span>learning_rate<span class="token punctuation">)</span>
        train <span class="token operator">=</span> optimizer<span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

    init <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
        sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init<span class="token punctuation">)</span>
        <span class="token keyword">for</span> step <span class="token keyword">in</span> range<span class="token punctuation">(</span>NUM_STEPS<span class="token punctuation">)</span><span class="token punctuation">:</span>
            sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train<span class="token punctuation">,</span>feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x <span class="token punctuation">:</span>x_data <span class="token punctuation">,</span> y_true <span class="token punctuation">:</span> y_data<span class="token punctuation">}</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> step <span class="token operator">%</span> <span class="token number">5</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span>step <span class="token punctuation">,</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span>w<span class="token punctuation">,</span>b<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                wb<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span>w<span class="token punctuation">,</span>b<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h3><p>一般用来进行二分类任务，输出一个0-1之间地离散二值结果，通过sigmoid函数来将数值映射到0到1之间，之后通过阈值分类器来将0到1之间的值转换为0或1，与之前代码的唯一不同是损失函数部分</p>
<pre class="line-numbers language-pyhton"><code class="language-pyhton">with tf.name_scope('loss') as scope:
loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = y_true , logits = y_pred)
loss = tf.reduce_mean(loss)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h2 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h2><p>层中的神经元只与前一层中的一小块区域连接，而不是采取全连接方式，主要由输入层，卷积层，ReLU层，池化层和全连接层构成(一般将卷积层和ReLU层一起称为卷积层)具体说来，卷积层和全连接层（CONV/FC）对输入执行变换操作的时候，不仅会用到激活函数，还会用到很多参数，即神经元的权值w和偏差b；而ReLU层和池化层则是进行一个固定不变的函数操作。卷积层和全连接层中的参数会随着梯度下降被训练，这样卷积神经网络计算出的分类评分就能和训练集中的每个图像的标签吻合了。</p>
<h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>参数由一些可学习的滤波器集合构成，只观察输入数据中的一小部分，由于卷积有“权值共享”这样的特性，可以降低参数的数量，防止参数过多造成过拟合。每个神经元连接的空间大小叫做神经元的感受野，深度与输入相同，但宽高是局部的。输出数据体和使用的滤波器的数量一致，将沿着深度方向排列。有时候在输入数据体的边缘使用0进行填充，使得滤波器可以平滑地在数据上滑动，一般是用来保持数据体的空间尺寸使输入输出宽高相同。如果在一个深度切片中的所有权重都使用同一个权重向量，那么卷积层的前向传播在每个深度切片中可以看做是在计算神经元权重和输入数据体的卷积（这就是“卷积层”名字由来）。这也是为什么总是将这些权重集合称为滤波器（filter）（或卷积核（kernel）），因为它们和输入进行了卷积。简单来说，就是一个在原始数据上以步长为长度不断移动的一个矩阵，层数与原始数据一致，将每个对应位置的数据进行乘积并且将每层的值相加，即为输出的一个数据，例如RGB通道下就是三层滤波器所得相加填入新的矩阵当中。</p>
<h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><p>用来简化数据，减少计算量，有最大池化和平均池化，使用较多的是最大池化，通过找出某一个区域内的最大值/平均值来缩小数据，一般使用的参数是f=2，p=2 恰好为缩小数据为原来的一半，并且反向传播没有参数适用于池化，这一过程是静态过程，参数都是手动设定，或是交叉验证得到的，只用于简化数据，提取特征。</p>
<h3 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3><p>将池化层简化后的数据进行提取，将特征整合到一起，输出为一个值，主要作用是减小特征位置对于结果产生的影响，将结果进行分类，一般不止一层，需要将提取出来的特征神经元激活后，通过不同神经元激活的组合，再提取出结果</p>
<p>简单的卷积实现mnist识别,将测试过程分为每个大小为1000幅图的十块</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> tensorflow<span class="token punctuation">.</span>compat<span class="token punctuation">.</span>v1 <span class="token keyword">as</span> tf
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>examples<span class="token punctuation">.</span>tutorials<span class="token punctuation">.</span>mnist <span class="token keyword">import</span> input_data
DATA_DIR <span class="token operator">=</span> <span class="token string">'/tmp/data'</span>
NUM_STEPS <span class="token operator">=</span> <span class="token number">10000</span>
MINIBATCH_SIZE <span class="token operator">=</span> <span class="token number">100</span>
tf<span class="token punctuation">.</span>disable_eager_execution<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">weight_variable</span><span class="token punctuation">(</span>shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
    initial <span class="token operator">=</span> tf<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span>shape <span class="token punctuation">,</span> stddev<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>initial<span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">bias_variable</span><span class="token punctuation">(</span>shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
    initial <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token number">0.1</span> <span class="token punctuation">,</span> shape <span class="token operator">=</span> shape<span class="token punctuation">)</span>
    <span class="token keyword">return</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>initial<span class="token punctuation">)</span>
<span class="token keyword">def</span> conv2d <span class="token punctuation">(</span>x <span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>x <span class="token punctuation">,</span> w <span class="token punctuation">,</span> strides <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span> <span class="token punctuation">,</span><span class="token number">1</span> <span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token string">'SAME'</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">max_pool_2x2</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>max_pool<span class="token punctuation">(</span>x <span class="token punctuation">,</span> ksize <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span> <span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> strides <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'SAME'</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">conv_layer</span><span class="token punctuation">(</span>input <span class="token punctuation">,</span> shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
    w <span class="token operator">=</span> weight_variable<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>
    b <span class="token operator">=</span> bias_variable<span class="token punctuation">(</span><span class="token punctuation">[</span>shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>conv2d<span class="token punctuation">(</span>input<span class="token punctuation">,</span>w<span class="token punctuation">)</span><span class="token operator">+</span>b<span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">full_layer</span><span class="token punctuation">(</span>input <span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    in_size <span class="token operator">=</span> int<span class="token punctuation">(</span>input<span class="token punctuation">.</span>get_shape<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    w <span class="token operator">=</span> weight_variable<span class="token punctuation">(</span><span class="token punctuation">[</span>in_size<span class="token punctuation">,</span>size<span class="token punctuation">]</span><span class="token punctuation">)</span>
    b <span class="token operator">=</span> bias_variable<span class="token punctuation">(</span><span class="token punctuation">[</span>size<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>input<span class="token punctuation">,</span>w<span class="token punctuation">)</span> <span class="token operator">+</span> b
x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32 <span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span>None <span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y_ <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32 <span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span>None <span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
x_image <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
conv1 <span class="token operator">=</span> conv_layer<span class="token punctuation">(</span>x_image <span class="token punctuation">,</span> shape <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
conv1_pool <span class="token operator">=</span> max_pool_2x2<span class="token punctuation">(</span>conv1<span class="token punctuation">)</span>

conv2 <span class="token operator">=</span> conv_layer<span class="token punctuation">(</span>conv1_pool <span class="token punctuation">,</span> shape <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
conv2_pool <span class="token operator">=</span> max_pool_2x2<span class="token punctuation">(</span>conv2<span class="token punctuation">)</span>

conv2_flat <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>conv2_pool<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">*</span><span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
full_1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>full_layer<span class="token punctuation">(</span>conv2_flat <span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

keep_prob <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
full1_drop <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>full_1 <span class="token punctuation">,</span> keep_prob <span class="token operator">=</span> keep_prob<span class="token punctuation">)</span>

y_conv <span class="token operator">=</span> full_layer<span class="token punctuation">(</span>full1_drop <span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

minst <span class="token operator">=</span> input_data<span class="token punctuation">.</span>read_data_sets<span class="token punctuation">(</span>DATA_DIR <span class="token punctuation">,</span> one_hot<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
cross_entropy <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax_cross_entropy_with_logits<span class="token punctuation">(</span>logits <span class="token operator">=</span> y_conv <span class="token punctuation">,</span> labels <span class="token operator">=</span> y_<span class="token punctuation">)</span> <span class="token punctuation">)</span>
train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>cross_entropy<span class="token punctuation">)</span>
correct_prediction <span class="token operator">=</span> tf<span class="token punctuation">.</span>equal<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>y_conv <span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">,</span> tf<span class="token punctuation">.</span>arg_max<span class="token punctuation">(</span>y_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
accuracy <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>correct_prediction <span class="token punctuation">,</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>NUM_STEPS<span class="token punctuation">)</span><span class="token punctuation">:</span>
        batch <span class="token operator">=</span> minst<span class="token punctuation">.</span>train<span class="token punctuation">.</span>next_batch<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            train_accuracy <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>accuracy <span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span>batch<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token punctuation">,</span> y_<span class="token punctuation">:</span>batch<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token punctuation">,</span> keep_prob <span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"step {} , train accuracy {}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>i<span class="token punctuation">,</span>train_accuracy<span class="token punctuation">)</span><span class="token punctuation">)</span>
        sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train_step <span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span>batch<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token punctuation">,</span> y_<span class="token punctuation">:</span>batch<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token punctuation">,</span> keep_prob <span class="token punctuation">:</span> <span class="token number">0.5</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
        X <span class="token operator">=</span> minst<span class="token punctuation">.</span>test<span class="token punctuation">.</span>images<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">1000</span><span class="token punctuation">,</span><span class="token number">784</span><span class="token punctuation">)</span>
        Y <span class="token operator">=</span> minst<span class="token punctuation">.</span>test<span class="token punctuation">.</span>labels<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">1000</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>
        test_accuracy <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">[</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>accuracy <span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span>X<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token punctuation">,</span> y_<span class="token punctuation">:</span>Y<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token punctuation">,</span> keep_prob <span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"test accuracy: {}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>test_accuracy<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h3><p>深度残差网络（Deep residual network, ResNet）的提出是CNN图像史上的一件里程碑事件.通过引入残差学习的方法来解决网络在随着深度增加时出现的准确度饱和下降，梯度爆炸以及消失的难以训练的问题。对于一个堆积结构，在输入x时，学到的特征为H(x)，现在希望其学到残差即 H(x)-x,这样即使残差为0时，也仅是在层之间做了恒等映射，至少不会性能下降，残差使得其会在本有的特征上学习到新的特征，有点类似电路中的短路`</p>

      </div>
  </article>

  <article class="post">
      
        
          <h1><a href="/2020/08/26/Tensorflow2.x学习笔记/">TensorFlow2.x学习笔记</a></h1>
        
      
      <div class="post-content ">
        
  




        <h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><p>创建变量等操作与1.x基本类似，但可以进行即时执行模式，与之前的图执行模式不同，语法更精炼简单。</p>
<pre class="line-numbers language-python"><code class="language-python">num_epoch <span class="token operator">=</span> <span class="token number">100000</span>
optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>learning_rate <span class="token operator">=</span> <span class="token number">5e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> e <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>GradientTape<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> tape<span class="token punctuation">:</span>
        y_pred <span class="token operator">=</span> a <span class="token operator">*</span> x <span class="token operator">+</span> b
        loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>square<span class="token punctuation">(</span>y <span class="token operator">-</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span>
    grads <span class="token operator">=</span> tape<span class="token punctuation">.</span>gradient<span class="token punctuation">(</span>loss <span class="token punctuation">,</span> variables<span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>apply_gradients<span class="token punctuation">(</span>grads_and_vars <span class="token operator">=</span> zip<span class="token punctuation">(</span>grads <span class="token punctuation">,</span> variables<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>可以直接调用GradientTape来进行梯度以及导数计算。上面的代码中声明了一个梯度下降优化器，可以通过计算的求导结果更新模型参数，从而最小化某个特定的损失函数，通过apply_gradients()方法来进行调用，函数内的参数为需要更新的变量以及损失函数关于该变量的偏导数。需要传入一个列表，每个元素为(偏导，变量)。</p>
<h2 id="模型与层"><a href="#模型与层" class="headerlink" title="模型与层"></a>模型与层</h2><p>使用TF内置的库Keras来进行模型的构建。<br>Keras里有两个重要的概念：<strong>层(Layer)</strong>和<strong>模型(model)</strong>,层将各种计算流程和变量进行了封装(全连接层，卷积层，池化层等)，模型则用于各种层进行连接。模型通过类的形式呈现，所以可以通过继承tf.keras.Model来定义自己的模型，需要重写<strong>init</strong>()和call(),继承模型后可以调用模型中的方法和属性。可以大量简化代码,下面是通过模型的方式编写的一个简单的线性回归，可以看出在进行计算处理部分与之前基本一致，但是关于模型变量的访问，以及模型初始化都方便了许多。通过在模型内部实例化了一个全连接层，并对其在call()中进行调用</p>
<pre class="line-numbers language-python"><code class="language-python">X <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4.0</span><span class="token punctuation">,</span> <span class="token number">5.0</span><span class="token punctuation">,</span> <span class="token number">6.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">20.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">Linear</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Model<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dense <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>
            units <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>
            activation<span class="token operator">=</span>None<span class="token punctuation">,</span>
            kernel_initializer <span class="token operator">=</span> tf<span class="token punctuation">.</span>zeros_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            bias_initializer <span class="token operator">=</span> tf<span class="token punctuation">.</span>zeros_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self <span class="token punctuation">,</span> input<span class="token punctuation">)</span><span class="token punctuation">:</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>input<span class="token punctuation">)</span>
        <span class="token keyword">return</span> output
model <span class="token operator">=</span> Linear<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>GradientTape<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> tape<span class="token punctuation">:</span>
        y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>square<span class="token punctuation">(</span>y_pred <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span>
    grads <span class="token operator">=</span> tape<span class="token punctuation">.</span>gradient<span class="token punctuation">(</span>loss <span class="token punctuation">,</span> model<span class="token punctuation">.</span>variables<span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>apply_gradients<span class="token punctuation">(</span>grads_and_vars <span class="token operator">=</span> zip<span class="token punctuation">(</span>grads <span class="token punctuation">,</span> model<span class="token punctuation">.</span>variables<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>variables<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>全连接层(Dense)</strong> 是最常用的层之一，对输入矩阵进行f(AW+b)的线性变换+激活函数操作，激活函数一般是Relu等等.包含的参数如下</p>
<ul>
<li>units 输出张量的维度</li>
<li>activation 激活函数 不指定时为f(x) = x</li>
<li>use_bias 添加偏置，默认为True</li>
<li>kernel_initializer,bias_initializer 权重，偏置的初始化器，默认为glort_uniform_initializer(很多层都默认使用)，使用ezeros_initializer表示初始化为0</li>
</ul>
<p><strong>softmax函数</strong>为了使得模型的输出能始终满足这两个条件，我们使用 Softmax 函数 （归一化指数函数， tf.nn.softmax ）对模型的原始输出进行归一化 。不仅如此，softmax 函数能够凸显原始向量中最大的值，并抑制远低于最大值的其他分量，这也是该函数被称作 softmax 函数的原因（即平滑化的 argmax 函数）。</p>
<h3 id="模型的训练"><a href="#模型的训练" class="headerlink" title="模型的训练"></a>模型的训练</h3><p>tf.keras.losses 和 tf.keras.optimizer<br>需要定义一些模型超参数</p>
<ul>
<li><p>num_epochs = 5</p>
</li>
<li><p>batch_size = 50</p>
</li>
<li><p>learning_rate = 0.001<br>之后实例化模型和优化器，迭代进行数据的读取以及模型的训练步骤如下</p>
</li>
<li><p>从 DataLoader 中随机取一批训练数据；</p>
</li>
<li><p>将这批数据送入模型，计算出模型的预测值；</p>
</li>
<li><p>将模型预测值与真实值进行比较，计算损失函数（loss）。这里使用 tf.keras.losses 中的交叉熵函数作为损失函数</p>
</li>
<li><p>计算损失函数关于模型变量的导数；</p>
</li>
<li><p>将求出的导数值传入优化器，使用优化器的 apply_gradients 方法更新模型参数以最小化损失函数</p>
</li>
</ul>
<h3 id="模型的评估"><a href="#模型的评估" class="headerlink" title="模型的评估"></a>模型的评估</h3><p>使用tf.keras.metrics中的SparseCategoricalAccuracy来评估模型在测试集上的性能，通过将预测结果与真是结果相比较，输出正确的占比。通过update_state()方法向评估器输入预测值和真实值。其内部有变量来保存当前评估的指标的数值，最终通过result()方法输出最终评估值。</p>
<h3 id="代码汇总"><a href="#代码汇总" class="headerlink" title="代码汇总"></a>代码汇总</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token comment" spellcheck="true">#CNN with keras</span>
<span class="token keyword">class</span> <span class="token class-name">CNN</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Model<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>
            filters<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>             <span class="token comment" spellcheck="true"># 卷积层神经元（卷积核）数目</span>
            kernel_size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>     <span class="token comment" spellcheck="true"># 感受野大小</span>
            padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>         <span class="token comment" spellcheck="true"># padding策略（vaild 或 same）</span>
            activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu   <span class="token comment" spellcheck="true"># 激活函数</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pool1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>
            filters<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>
            kernel_size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span>
            activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pool2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>flatten <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Reshape<span class="token punctuation">(</span>target_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">7</span> <span class="token operator">*</span> <span class="token number">7</span> <span class="token operator">*</span> <span class="token number">64</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dense1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">1024</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dense2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>                  <span class="token comment" spellcheck="true"># [batch_size, 28, 28, 32]</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                       <span class="token comment" spellcheck="true"># [batch_size, 14, 14, 32]</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                       <span class="token comment" spellcheck="true"># [batch_size, 14, 14, 64]</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                       <span class="token comment" spellcheck="true"># [batch_size, 7, 7, 64]</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                     <span class="token comment" spellcheck="true"># [batch_size, 7 * 7 * 64]</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>dense1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                      <span class="token comment" spellcheck="true"># [batch_size, 1024]</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>dense2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                      <span class="token comment" spellcheck="true"># [batch_size, 10]</span>
        output <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> output
<span class="token comment" spellcheck="true"># MNISTLoader and MLP</span>
<span class="token keyword">class</span> <span class="token class-name">MNISTLoader</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        mnist <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>mnist
        <span class="token punctuation">(</span>self<span class="token punctuation">.</span>train_data<span class="token punctuation">,</span> self<span class="token punctuation">.</span>train_label<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>test_data<span class="token punctuation">,</span> self<span class="token punctuation">.</span>test_label<span class="token punctuation">)</span> <span class="token operator">=</span> mnist<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true"># MNIST中的图像默认为uint8（0-255的数字）。以下代码将其归一化到0-1之间的浮点数，并在最后增加一维作为颜色通道</span>
        self<span class="token punctuation">.</span>train_data <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>self<span class="token punctuation">.</span>train_data<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>      <span class="token comment" spellcheck="true"># [60000, 28, 28, 1]</span>
        self<span class="token punctuation">.</span>test_data <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>self<span class="token punctuation">.</span>test_data<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># [10000, 28, 28, 1]</span>
        self<span class="token punctuation">.</span>train_label <span class="token operator">=</span> self<span class="token punctuation">.</span>train_label<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># [60000]</span>
        self<span class="token punctuation">.</span>test_label <span class="token operator">=</span> self<span class="token punctuation">.</span>test_label<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>      <span class="token comment" spellcheck="true"># [10000]</span>
        self<span class="token punctuation">.</span>num_train_data<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_test_data <span class="token operator">=</span> self<span class="token punctuation">.</span>train_data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>test_data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">get_batch</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 从数据集中随机取出batch_size个元素并返回</span>
        index <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_train_data<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>train_data<span class="token punctuation">[</span>index<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>train_label<span class="token punctuation">[</span>index<span class="token punctuation">]</span>




<span class="token comment" spellcheck="true"># class MLP(tf.keras.Model):</span>
<span class="token comment" spellcheck="true">#     def __init__(self, *args, **kwargs):</span>
<span class="token comment" spellcheck="true">#         super().__init__(*args, **kwargs)</span>
<span class="token comment" spellcheck="true">#         self._flatten = tf.keras.layers.Flatten()</span>
<span class="token comment" spellcheck="true">#         self.dense1 = tf.keras.layers.Dense(units=100 , activation = tf.nn.relu)</span>
<span class="token comment" spellcheck="true">#         self.dense2 = tf.keras.layers.Dense(units=10)</span>
<span class="token comment" spellcheck="true">#     def call(self, inputs):</span>
<span class="token comment" spellcheck="true">#         x = self._flatten(inputs)</span>
<span class="token comment" spellcheck="true">#         x = self.dense1(x)</span>
<span class="token comment" spellcheck="true">#         x = self.dense2(x)</span>
<span class="token comment" spellcheck="true">#         output = tf.nn.softmax(x)</span>
<span class="token comment" spellcheck="true">#         return output</span>
num_epochs <span class="token operator">=</span> <span class="token number">5</span>
batch_size <span class="token operator">=</span> <span class="token number">50</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.001</span>
model <span class="token operator">=</span> CNN<span class="token punctuation">(</span><span class="token punctuation">)</span>
data_loader <span class="token operator">=</span> MNISTLoader<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>learning_rate <span class="token operator">=</span> learning_rate<span class="token punctuation">)</span>
num_batches <span class="token operator">=</span> int<span class="token punctuation">(</span>data_loader<span class="token punctuation">.</span>num_train_data <span class="token operator">//</span> batch_size <span class="token operator">*</span> num_epochs<span class="token punctuation">)</span>
<span class="token keyword">for</span> batch_index <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_batches<span class="token punctuation">)</span><span class="token punctuation">:</span>
    X <span class="token punctuation">,</span> y <span class="token operator">=</span> data_loader<span class="token punctuation">.</span>get_batch<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span>
    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>GradientTape<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> tape<span class="token punctuation">:</span>
        y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>sparse_categorical_crossentropy<span class="token punctuation">(</span>y_true<span class="token operator">=</span>y <span class="token punctuation">,</span> y_pred<span class="token operator">=</span>y_pred<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"batch %d: loss %f"</span><span class="token operator">%</span><span class="token punctuation">(</span>batch_index <span class="token punctuation">,</span> loss<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    grads <span class="token operator">=</span> tape<span class="token punctuation">.</span>gradient<span class="token punctuation">(</span>loss <span class="token punctuation">,</span> model<span class="token punctuation">.</span>variables<span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>apply_gradients<span class="token punctuation">(</span>grads_and_vars <span class="token operator">=</span> zip<span class="token punctuation">(</span>grads <span class="token punctuation">,</span> model<span class="token punctuation">.</span>variables<span class="token punctuation">)</span><span class="token punctuation">)</span>
sparse_categorical_accuracy <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>SparseCategoricalAccuracy<span class="token punctuation">(</span><span class="token punctuation">)</span>
num_batches <span class="token operator">=</span> int<span class="token punctuation">(</span>data_loader<span class="token punctuation">.</span>num_test_data <span class="token operator">//</span> batch_size<span class="token punctuation">)</span>
<span class="token keyword">for</span> batch_index <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_batches<span class="token punctuation">)</span><span class="token punctuation">:</span>
    start_index <span class="token punctuation">,</span> end_index <span class="token operator">=</span> batch_index <span class="token operator">*</span> batch_size <span class="token punctuation">,</span> <span class="token punctuation">(</span>batch_index <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> batch_size
    y_pred <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>data_loader<span class="token punctuation">.</span>test_data<span class="token punctuation">[</span>start_index <span class="token punctuation">:</span> end_index<span class="token punctuation">]</span><span class="token punctuation">)</span>
    sparse_categorical_accuracy<span class="token punctuation">.</span>update_state<span class="token punctuation">(</span>y_true <span class="token operator">=</span> data_loader<span class="token punctuation">.</span>test_label<span class="token punctuation">[</span>start_index <span class="token punctuation">:</span> end_index<span class="token punctuation">]</span> <span class="token punctuation">,</span> y_pred<span class="token operator">=</span> y_pred<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"test accuracy : %f"</span><span class="token operator">%</span>sparse_categorical_accuracy<span class="token punctuation">.</span>result<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#using Model for linear regression</span>
<span class="token comment" spellcheck="true"># X = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])</span>
<span class="token comment" spellcheck="true"># y = tf.constant([[10.0], [20.0]])</span>

<span class="token comment" spellcheck="true"># class Linear(tf.keras.Model):</span>
<span class="token comment" spellcheck="true">#     def __init__(self):</span>
<span class="token comment" spellcheck="true">#         super().__init__()</span>
<span class="token comment" spellcheck="true">#         self.dense = tf.keras.layers.Dense(</span>
<span class="token comment" spellcheck="true">#             units = 1,</span>
<span class="token comment" spellcheck="true">#             activation=None,</span>
<span class="token comment" spellcheck="true">#             kernel_initializer = tf.zeros_initializer(),</span>
<span class="token comment" spellcheck="true">#             bias_initializer = tf.zeros_initializer()</span>
<span class="token comment" spellcheck="true">#         )</span>
<span class="token comment" spellcheck="true">#     def call(self , input):</span>
<span class="token comment" spellcheck="true">#         output = self.dense(input)</span>
<span class="token comment" spellcheck="true">#         return output</span>
<span class="token comment" spellcheck="true"># model = Linear()</span>
<span class="token comment" spellcheck="true"># optimizer = tf.keras.optimizers.SGD(lr=0.01)</span>
<span class="token comment" spellcheck="true"># for i in range(100):</span>
<span class="token comment" spellcheck="true">#     with tf.GradientTape() as tape:</span>
<span class="token comment" spellcheck="true">#         y_pred = model(X)</span>
<span class="token comment" spellcheck="true">#         print(model.variables)</span>
<span class="token comment" spellcheck="true">#         loss = tf.reduce_mean(tf.square(y_pred - y))</span>
<span class="token comment" spellcheck="true">#     grads = tape.gradient(loss , model.variables)</span>
<span class="token comment" spellcheck="true">#     optimizer.apply_gradients(grads_and_vars = zip(grads , model.variables))</span>
<span class="token comment" spellcheck="true"># print(model.variables)</span>
<span class="token comment" spellcheck="true"># 1st the linear regression</span>
<span class="token comment" spellcheck="true"># X_raw = np.array([2013, 2014, 2015, 2016, 2017], dtype=np.float32)</span>
<span class="token comment" spellcheck="true"># y_raw = np.array([12000, 14000, 15000, 16500, 17500], dtype=np.float32)</span>

<span class="token comment" spellcheck="true"># x = (X_raw - X_raw.min()) / (X_raw.max() - X_raw.min())</span>
<span class="token comment" spellcheck="true"># y = (y_raw - y_raw.min()) / (y_raw.max() - y_raw.min())</span>

<span class="token comment" spellcheck="true"># x = tf.constant(x)</span>
<span class="token comment" spellcheck="true"># y = tf.constant(y)</span>

<span class="token comment" spellcheck="true"># a = tf.Variable(initial_value = 0.)</span>
<span class="token comment" spellcheck="true"># b = tf.Variable(initial_value = 0 , dtype = tf.float32)</span>
<span class="token comment" spellcheck="true"># variables = [a,b]</span>

<span class="token comment" spellcheck="true"># num_epoch = 100000</span>
<span class="token comment" spellcheck="true"># optimizer = tf.keras.optimizers.SGD(learning_rate = 5e-4)</span>
<span class="token comment" spellcheck="true"># for e in range(num_epoch):</span>
<span class="token comment" spellcheck="true">#     with tf.GradientTape() as tape:</span>
<span class="token comment" spellcheck="true">#         y_pred = a * x + b</span>
<span class="token comment" spellcheck="true">#         loss = tf.reduce_sum(tf.square(y - y_pred))</span>
<span class="token comment" spellcheck="true">#     grads = tape.gradient(loss , variables)</span>
<span class="token comment" spellcheck="true">#     optimizer.apply_gradients(grads_and_vars = zip(grads , variables))</span>
<span class="token comment" spellcheck="true"># print(a,b)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

      </div>
  </article>

  <article class="post">
      
        
          <h1><a href="/2019/12/26/Mybatis/">Mybatis</a></h1>
        
      
      <div class="post-content ">
        
  




        <h2 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h2><ol>
<li>框架的概念:软件开发中的一套解决方案，不同方案可以解决不同的问题，封装了许多的细节，可以使开发效率大幅度提高。</li>
<li>三层架构：<ul>
<li>表现层：数据的展示</li>
<li>业务层：处理业务需求</li>
<li>持久层：与数据库交互</li>
</ul>
</li>
<li>持久层的技术解决方案<ul>
<li>JDBC技术<ul>
<li>Connection</li>
<li>PreparedStatement</li>
<li>ResultSet</li>
</ul>
</li>
<li>Spring的JdbcTemplate:Spring对jdbc的简单封装</li>
<li>Apache的DBUtiles:与SPring的jdbcTemplate很像，也是对与jdbc的简单封装</li>
</ul>
</li>
<li>mybatis是一个持久层的框架，封装了jdbc操作的细节，使用了ORM思想，实现了结果集的封装。<br>ORM(Object Relational Mapping)将数据库表和实体类及实体类的属性对应起来可以操作实体类就实现操作数据库表</li>
</ol>
<h2 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h2><ol>
<li><p>使用IDE创建出一个maven项目</p>
</li>
<li><p>选择项目地打包方式，在项目中引入依赖</p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token operator">&lt;</span>groupId<span class="token operator">></span>com<span class="token punctuation">.</span>itheima<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>
 <span class="token operator">&lt;</span>artifactId<span class="token operator">></span>first_mybatis<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>
 <span class="token operator">&lt;</span>version<span class="token operator">></span><span class="token number">1.0</span><span class="token operator">-</span>SNAPSHOT<span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>
 <span class="token operator">&lt;</span>packaging<span class="token operator">></span>jar<span class="token operator">&lt;</span><span class="token operator">/</span>packaging<span class="token operator">></span>
 <span class="token operator">&lt;</span>dependencies<span class="token operator">></span>
     <span class="token operator">&lt;</span>dependency<span class="token operator">></span>
     <span class="token operator">&lt;</span>groupId<span class="token operator">></span>org<span class="token punctuation">.</span>mybatis<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>
     <span class="token operator">&lt;</span>artifactId<span class="token operator">></span>mybatis<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>
     <span class="token operator">&lt;</span>version<span class="token operator">></span><span class="token number">3.4</span><span class="token punctuation">.</span><span class="token number">5</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>
 <span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span>
     <span class="token operator">&lt;</span>dependency<span class="token operator">></span>
         <span class="token operator">&lt;</span>groupId<span class="token operator">></span>mysql<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>
         <span class="token operator">&lt;</span>artifactId<span class="token operator">></span>mysql<span class="token operator">-</span>connector<span class="token operator">-</span>java<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>
         <span class="token operator">&lt;</span>version<span class="token operator">></span><span class="token number">6.0</span><span class="token punctuation">.</span><span class="token number">5</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>
     <span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span>
     <span class="token operator">&lt;</span>dependency<span class="token operator">></span>
         <span class="token operator">&lt;</span>groupId<span class="token operator">></span>log4j<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>
         <span class="token operator">&lt;</span>artifactId<span class="token operator">></span>log4j<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>
         <span class="token operator">&lt;</span>version<span class="token operator">></span><span class="token number">1.2</span><span class="token punctuation">.</span><span class="token number">12</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>
     <span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span>
     <span class="token operator">&lt;</span>dependency<span class="token operator">></span>
         <span class="token operator">&lt;</span>groupId<span class="token operator">></span>junit<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>
         <span class="token operator">&lt;</span>artifactId<span class="token operator">></span>junit<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>
         <span class="token operator">&lt;</span>version<span class="token operator">></span><span class="token number">4.12</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>
     <span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span>
 <span class="token operator">&lt;</span><span class="token operator">/</span>dependencies<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p>接下来在src中创建数据库表中对应的对象，且要implements Serializable使对象序列化接下来是一些基本你的操作，将所有属性私有化留出get和set方法</p>
</li>
<li><p>接下来创建出一个IuserDao的接口(I的意思只是Interface)称为用户的持久层接口，在其中创建查询所有操作的序列。</p>
</li>
<li><p>配置mybtis的环境，创建一个xml文件在resources文件夹下,在创建完成后需要在相应的mapper位置下建立对应的配置，且引入mapper的约束。</p>
</li>
</ol>
<p>Config配置</p>
<pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8" ?></span>
<span class="token doctype">&lt;!DOCTYPE configuration
        PUBLIC "-//mybatis.org//DTD Config 3.0//EN"
        "http://mybatis.org/dtd/mybatis-3-config.dtd"></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
    <span class="token comment" spellcheck="true">&lt;!--配置环境--></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>environments</span> <span class="token attr-name">default</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>mysql<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>
        <span class="token comment" spellcheck="true">&lt;!--配置mysql环境--></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>environment</span> <span class="token attr-name">id</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>mysql<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>
            <span class="token comment" spellcheck="true">&lt;!--配置事务类型--></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>transactionManager</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>JDBC<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>transactionManager</span><span class="token punctuation">></span></span>
            <span class="token comment" spellcheck="true">&lt;!--配置连接池--></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dataSource</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>POOLED<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>
                <span class="token comment" spellcheck="true">&lt;!--配置连接数据库的基本信息--></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>driver<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>com.mysql,jdbc.Driver<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>url<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>jdbc:mysql://localhost:3306/mybatis<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>username<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>root<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>password<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>root<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dataSource</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>environment</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>environments</span><span class="token punctuation">></span></span>

    <span class="token comment" spellcheck="true">&lt;!--指定映射配置文件--></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mappers</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mapper</span> <span class="token attr-name">resource</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>com/itheima.dao/IuserDao.xml<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mappers</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>mapper的配置</p>
<pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8" ?></span>
<span class="token doctype">&lt;!DOCTYPE mapper
        PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
        "http://mybatis.org/dtd/mybatis-3-mapper.dtd" ></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mapper</span> <span class="token attr-name">namespace</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>com.itheima.dao.IUserDao<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>
    <span class="token comment" spellcheck="true">&lt;!--配置查询所有--></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>select</span> <span class="token attr-name">id</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>findAll<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>
        select * from USER
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>select</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mapper</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>至此环境搭建基本完成，在进行这些操作前需要将maven项目的环境搭建好，并建立好仓库等。</p>
<h2 id="mybatis的实例"><a href="#mybatis的实例" class="headerlink" title="mybatis的实例"></a>mybatis的实例</h2><p>1.在test的java文件夹中以main函数来进行测试，且使用了工厂模式来进行sql语句的执行</p>
<pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception<span class="token punctuation">{</span>
        <span class="token comment" spellcheck="true">//1.读取配置文件</span>
        InputStream inputStream <span class="token operator">=</span> Resources<span class="token punctuation">.</span><span class="token function">getResourceAsStream</span><span class="token punctuation">(</span><span class="token string">"SqlMapConfig.xml"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment" spellcheck="true">//2.创建SQL Session Factory工厂</span>
        SqlSessionFactoryBuilder builder <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SqlSessionFactoryBuilder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        SqlSessionFactory factory <span class="token operator">=</span> builder<span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span>inputStream<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment" spellcheck="true">//3.使用工厂生产SqlSession对象</span>
        SqlSession session <span class="token operator">=</span> factory<span class="token punctuation">.</span><span class="token function">openSession</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment" spellcheck="true">//4.使用SQL Session创建Dao接口代理对象</span>
        IUserDao userDao <span class="token operator">=</span> session<span class="token punctuation">.</span><span class="token function">getMapper</span><span class="token punctuation">(</span>IUserDao<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment" spellcheck="true">//5.使用代理对象执行方法</span>
        List<span class="token operator">&lt;</span>User<span class="token operator">></span> users<span class="token punctuation">;</span>
        users <span class="token operator">=</span> userDao<span class="token punctuation">.</span><span class="token function">findAll</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span>User user <span class="token operator">:</span> users<span class="token punctuation">)</span><span class="token punctuation">{</span>
            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>user<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        <span class="token comment" spellcheck="true">//6.释放资源</span>
        session<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        inputStream<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>执行后发现报错并不如愿，理想中的报错应该是返回由于映射的没有返回结果而报错，最终发现是自己的mapper地址写错，以及jdbc的驱动加载写错。</p>
<ul>
<li><p>mybatis的映射配置文件位置必须和dao接口的包接口相同</p>
</li>
<li><p>映射配置文件mapper的标签namespace属性取值必须是dao接口的全限定类名</p>
</li>
<li><p>映射配置文件的操作配置，id属性取值必须是dao接口的方法名。</p>
</li>
</ul>
<h3 id="实例中使用到的几个类"><a href="#实例中使用到的几个类" class="headerlink" title="实例中使用到的几个类"></a>实例中使用到的几个类</h3><ol>
<li>class Resources</li>
<li>class SqlSessionFactoryBuilder</li>
<li>interface SqlSessionFactory</li>
<li>interface SqlSession</li>
</ol>
<p>在符合上面的几个条件的情况下，就不需要再写dao的实现类了。</p>
<h3 id="注解方式来使用mybatis"><a href="#注解方式来使用mybatis" class="headerlink" title="注解方式来使用mybatis"></a>注解方式来使用mybatis</h3><p>则可以删除每个dao对应的dao.xml改为@select注解，并且指定SQL语句，在config文件中配置mappper时，使用class属性指定dao接口的全限定类名。</p>
<h2 id="自定义MyBatis"><a href="#自定义MyBatis" class="headerlink" title="自定义MyBatis"></a>自定义MyBatis</h2><ol>
<li><p>首先需要有数据库的连接信息，通过连接信息，可以创建Connection对象，接下来需要映射的配置信息，最后从映射中配置需要的SQL语句。就可以获取PreparedStatement。通过dom4j来解析这些xml配置。</p>
</li>
<li><p>根据配置文件的细腻些创建Connection对象，获取预处理对象PrepareSatement接下来执行查询，将遍历的结果集封装，将结果返回。</p>
</li>
</ol>

      </div>
  </article>


  <nav class="pagination clearfix">
  <ul>
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-chevron-circle-right" aria-hidden="true"></i></a>
  </ul>
</nav>


</section>
    <footer id="footer" role="contentinfo">
    <div>&copy; 2023 <a href="/">Kopaba</a>.
    Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Designed by <a href="http://rainylog.com" target="_blank">Rainy.</a>
	</div>
</footer><!-- end #footer -->

  </div>
  <script src="/lib/fancybox/dist/jquery.fancybox.min.js"></script>

  <script src="/js/helper.js"></script>
  <script src="/js/_third-party/gitment.js"></script>
</body>
</html>